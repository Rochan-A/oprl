model: filev2 # one_state, five_state, gridworld, file, filev2
# if using gridworld, specify the gridworld env name
# eg. MiniGrid-SimpleCrossingS11N5-v0 MiniGrid-Empty-8x8-v0
# MiniGrid-LavaCrossingS11N5-v0 MiniGrid-LavaGapS7-v0 MiniGrid-FourRooms-v0
env: MiniGrid-Empty-8x8-v0
map_path: ./maps/new_lava_small_rew.txt
gamma: 0.9
seed: 0

env_mods:
  # (num of timesteps after reward is actually returned, except for terminal state)
  delay: None # inf, int, None
  state_bonus: False
  action_bonus: False
  distance_bonus: False

init: # How to initialize values (opt(1)/pes(-1)/zero/rand)
  Q: rand
  V: rand

# number of times to repeat Q learning algos due to randomness in e-greedy policy
exp:
  repeat: 20
  steps: 10000 # episodes
  exploration_steps: 40 # Explore for these many steps (with prob = 1) ignoring decay (set to 0 if you want to use epsilon decay)

# Perform select experiments ('val_iter', 'q', 'dq', 'pq', 'mmq', 'meanvar', 'mmbq', 'mmbq_v2')
perform: ['val_iter', 'q', 'dq', 'pq', 'mmq', 'mmbq', 'mmbq_v2'] # 'val_iter', 'q', 'dq', 'mmq', 'pq', 'mmbq_v2'

value_iteration_theta: 0.0001

q_learning:
  alpha: 0.05
  epsilon:
    strat: exp_interval  # Espilon decay to use (const/exp/linear)
    start: 0.1    # Starting value (for const, this value is used at every step)
    end: 0.01     # End value (for linear)
    decay: 0.99  # Epsilon decay rate
    steps: 40   # Number of steps to explore (Used for linear to get decay rate)
  use_buffer: True
  buffer_size: 100
  minibatch_size: 10

dq_learning:
  alpha: 0.05
  epsilon:
    strat: exp_interval
    start: 0.1
    end: 0.01
    decay: 0.99
    steps: 40
  use_buffer: True
  buffer_size: 100
  minibatch_size: 10

pessimistic_q_learning:
  alpha: 0.05
  epsilon:
    strat: exp_interval
    start: 0.1
    end: 0.01
    decay: 0.99
    steps: 40
  pessimism_coeff: 0.1
  use_buffer: True
  buffer_size: 100
  minibatch_size: 10

mmq_learning:
  alpha: 0.05
  epsilon:
    strat: exp_interval
    start: 0.1
    end: 0.01
    decay: 0.99
    steps: 40
  estimator_pools: [2, 4, 6]
  buffer_size: 100
  minibatch_size: 10

mmbq_learning:
  alpha: 0.05
  epsilon:
    strat: exp_interval
    start: 0.1
    end: 0.01
    decay: 0.99
    steps: 40
  max_estimators: 6
  cum_len: 10
  bandit_lr: 0.05
  buffer_size: 100
  minibatch_size: 10

meanvar_q_learning:
  alpha: 0.05
  epsilon:
    strat: exp_interval
    start: 0.1
    end: 0.01
    decay: 0.99
    steps: 40
  coeff: 0.1
  buffer_size: 100
